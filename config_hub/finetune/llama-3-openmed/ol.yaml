checkpoint_dir: checkpoints/aaditya/Llama3-OpenBioLLM-70B
out_dir: ???
precision: bf16-true
quantize: bnb.nf4-dq
devices: 1 # the number of devices
lora:
  r: 256
  alpha: 512
  dropout: 0.90
  query: True
  key: False
  value: True
  projection: False
  mlp: False
  head: False
data:
  class_path: litgpt.data.OL
  init_args:
    mask_prompt: False
    prompt_style: ol
    ignore_index: -100
    seed: 1337
    num_workers: 4
    download_dir: ???
    file_name: gt_training_split_on_docs.json
    file_name_validation: gt_val_split_on_docs.json
    balance_cfg: 
      classes:
        - RELATION
      percentage: 0.5
train:
  save_interval: 40
  log_interval: 16
  global_batch_size: 32
  micro_batch_size: 2
  lr_warmup_steps: 100
  epochs: 20
  max_steps: null
  max_seq_length: 256
  learning_rate: 3e-5
  weight_decay: 0.02
  beta1: 0.9
  beta2: 0.95
logger_args:
  experiment_name: clinkart_Llama3-OpenBioLLM-70B
  run_name: qlora_qv_r256_balanced05_dropout090_wd002
  tracking_uri: ???
  run_id: null
  synchronous: False
eval:
  interval: 40
  max_new_tokens: 100
  qualitative_val_sample_idx: 1
  temperature: 0
seed: 1337